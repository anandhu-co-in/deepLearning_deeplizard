{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels =  []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example data: \n",
    "- An experiemental drug was tested on individuals from ages 13 to 100. \n",
    "- The trial had 2100 participants. Half were under 65 years old, half were over 65 years old.\n",
    "- 95% of patientes 65 or older experienced side effects.\n",
    "- 95% of patients under 65 experienced no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 65, 39, 77, 27, 93, 14, 91, 23, 76, 49, 87, 14, 78, 14, 85, 37, 91, 41, 78, 22, 87, 64, 82, 54, 91, 23, 70, 34, 98, 44, 92, 26, 68, 59, 84, 15, 99, 54, 70, 27, 74, 44, 82, 64, 71, 26, 97, 15, 70, 50, 69, 39, 65, 21, 65, 36, 87, 23, 83, 29, 74, 49, 86, 30, 70, 16, 90, 49, 68, 48, 71, 14, 98, 61, 75, 64, 71, 47, 70, 39, 95, 26, 80, 37, 93, 41, 78, 54, 88, 53, 72, 33, 88, 51, 68, 33, 71, 46, 76, 46, 74, 43, 84, 14, 99, 36, 89, 50, 76, 16, 77, 18, 66, 14, 84, 58, 73, 51, 98, 25, 74, 43, 97, 57, 98, 43, 97, 36, 98, 22, 76, 59, 94, 21, 74, 39, 82, 64, 80, 13, 99, 18, 87, 21, 82, 60, 100, 34, 83, 36, 84, 25, 66, 43, 72, 45, 77, 56, 85, 64, 66, 55, 72, 48, 75, 46, 73, 39, 66, 30, 66, 38, 91, 15, 66, 32, 72, 58, 70, 43, 69, 37, 79, 33, 88, 18, 77, 13, 69, 31, 92, 51, 67, 41, 70, 17, 86, 25, 79, 34, 74, 57, 75, 14, 82, 50, 82, 44, 92, 20, 93, 32, 73, 37, 73, 49, 71, 54, 86, 41, 73, 55, 86, 51, 94, 53, 78, 61, 98, 37, 89, 54, 80, 13, 69, 19, 95, 25, 91, 51, 91, 55, 70, 15, 98, 44, 100, 17, 72, 33, 68, 47, 78, 46, 71, 19, 69, 20, 74, 42, 73, 34, 66, 64, 66, 45, 97, 28, 85, 42, 73, 45, 93, 40, 69, 49, 96, 54, 78, 64, 80, 42, 68, 58, 71, 32, 92, 14, 93, 51, 66, 42, 97, 50, 83, 63, 100, 57, 89, 22, 81, 38, 84, 64, 89, 27, 88, 31, 80, 29, 90, 44, 94, 38, 97, 41, 80, 36, 83, 52, 72, 35, 90, 56, 95, 35, 65, 26, 90, 32, 76, 39, 89, 33, 83, 18, 88, 38, 87, 64, 83, 55, 96, 55, 96, 33, 99, 19, 89, 55, 92, 53, 91, 58, 93, 22, 85, 16, 85, 37, 86, 30, 86, 35, 92, 25, 80, 46, 80, 14, 91, 60, 67, 35, 97, 13, 71, 30, 72, 16, 84, 64, 89, 20, 77, 60, 98, 41, 91, 56, 97, 46, 99, 47, 97, 19, 97, 32, 98, 52, 66, 46, 77, 15, 95, 19, 80, 53, 84, 35, 71, 28, 76, 16, 83, 52, 84, 57, 80, 51, 95, 22, 76, 44, 85, 49, 84, 21, 72, 38, 92, 45, 70, 60, 83, 45, 76, 50, 100, 21, 97, 52, 88, 26, 82, 41, 94, 13, 89, 52, 66, 42, 72, 40, 85, 62, 86, 33, 96, 42, 73, 31, 65, 45, 88, 54, 75, 47, 96, 28, 68, 31, 77, 22, 77, 59, 94, 57, 87, 18, 87, 55, 92, 19, 87, 45, 67, 20, 71, 51, 75, 35, 93, 40, 93, 27, 77, 29, 65, 58, 92, 16, 97, 14, 94, 18, 85, 26, 77, 14, 68, 20, 87, 56, 80, 58, 84, 51, 79, 62, 69, 25, 68, 22, 92, 42, 79, 46, 93, 39, 74, 17, 79, 60, 72, 39, 75, 52, 66, 56, 91, 15, 90, 29, 89, 25, 70, 41, 98, 56, 80, 35, 98, 34, 73, 36, 68, 15, 76, 21, 71, 14, 95, 32, 68, 53, 87, 23, 92, 40, 73, 26, 81, 24, 84, 17, 83, 17, 66, 49, 65, 51, 93, 17, 96, 13, 99, 39, 89, 60, 79, 45, 91, 50, 76, 28, 85, 33, 69, 16, 70, 62, 90, 25, 100, 48, 89, 28, 88, 44, 93, 53, 96, 60, 77, 46, 83, 45, 97, 61, 83, 36, 68, 47, 97, 15, 88, 24, 71, 34, 72, 56, 97, 42, 78, 18, 73, 43, 89, 51, 98, 60, 91, 49, 87, 46, 68, 59, 94, 43, 84, 37, 96, 18, 67, 30, 98, 59, 79, 25, 90, 45, 76, 52, 93, 22, 100, 36, 84, 51, 96, 17, 69, 52, 84, 56, 89, 62, 99, 59, 95, 43, 68, 60, 75, 31, 88, 46, 88, 13, 90, 62, 86, 50, 69, 15, 78, 60, 76, 26, 84, 31, 66, 19, 66, 40, 68, 31, 82, 16, 97, 53, 79, 56, 96, 22, 74, 21, 86, 36, 70, 47, 95, 62, 78, 29, 82, 43, 99, 21, 98, 31, 97, 33, 76, 34, 75, 56, 92, 64, 99, 40, 76, 19, 72, 39, 71, 34, 97, 62, 89, 57, 75, 62, 87, 52, 81, 55, 91, 37, 70, 52, 91, 63, 75, 39, 93, 62, 76, 17, 90, 27, 73, 64, 69, 35, 95, 60, 70, 20, 73, 39, 89, 40, 86, 39, 82, 38, 89, 64, 91, 26, 78, 56, 92, 21, 79, 15, 81, 55, 89, 34, 68, 39, 66, 24, 71, 39, 97, 48, 70, 18, 96, 24, 90, 50, 77, 47, 66, 48, 97, 20, 91, 28, 97, 28, 95, 63, 76, 20, 73, 59, 78, 16, 88, 39, 75, 25, 79, 48, 89, 45, 94, 30, 77, 24, 93, 34, 78, 51, 96, 56, 79, 38, 70, 30, 90, 47, 81, 61, 78, 28, 73, 22, 97, 19, 94, 45, 78, 44, 97, 55, 77, 31, 79, 56, 72, 35, 94, 64, 91, 20, 88, 29, 79, 21, 74, 36, 76, 13, 81, 44, 91, 53, 88, 52, 66, 14, 84, 40, 76, 48, 91, 29, 99, 62, 82, 44, 91, 56, 74, 25, 73, 60, 82, 33, 83, 26, 69, 16, 72, 63, 79, 42, 89, 34, 100, 24, 80, 50, 71, 48, 99, 16, 84, 31, 80, 40, 89, 27, 100, 56, 74, 46, 100, 40, 73, 44, 71, 19, 89, 13, 72, 18, 85, 43, 94, 55, 69, 34, 66, 45, 79, 16, 90, 64, 98, 19, 88, 15, 75, 64, 97, 40, 92, 35, 84, 31, 66, 45, 83, 30, 98, 31, 73, 34, 95, 22, 81, 29, 71, 16, 95, 34, 76, 51, 88, 36, 77, 19, 100, 43, 95, 61, 65, 36, 94, 33, 91, 60, 81, 47, 91, 43, 73, 28, 75, 22, 81, 35, 68, 58, 93, 43, 73, 25, 89, 27, 100, 39, 70, 49, 76, 49, 89, 27, 73, 27, 76, 38, 88, 42, 98, 24, 98, 49, 71, 18, 71, 47, 76, 38, 75, 48, 97, 64, 98, 62, 82, 21, 82, 13, 87, 27, 100, 47, 91, 30, 66, 42, 100, 18, 83, 43, 67, 30, 78, 23, 73, 55, 98, 58, 87, 15, 66, 36, 65, 42, 74, 64, 66, 58, 66, 34, 88, 22, 75, 61, 88, 15, 86, 52, 89, 18, 99, 33, 96, 23, 87, 45, 93, 14, 99, 26, 66, 50, 90, 62, 88, 53, 84, 62, 90, 33, 80, 58, 98, 17, 80, 33, 98, 56, 78, 63, 74, 40, 78, 44, 86, 22, 92, 38, 73, 31, 89, 54, 68, 24, 71, 41, 93, 36, 84, 42, 96, 48, 85, 49, 74, 50, 84, 16, 88, 62, 78, 20, 78, 47, 98, 44, 98, 16, 92, 32, 85, 39, 87, 22, 84, 47, 87, 45, 67, 29, 93, 23, 82, 32, 92, 47, 80, 53, 83, 37, 73, 15, 100, 46, 77, 27, 76, 52, 65, 42, 83, 20, 75, 57, 67, 45, 66, 55, 84, 56, 66, 22, 85, 34, 71, 36, 90, 17, 91, 31, 92, 35, 70, 19, 98, 38, 98, 57, 68, 44, 80, 21, 65, 29, 77, 64, 89, 48, 90, 37, 68, 48, 89, 54, 89, 29, 77, 22, 71, 36, 97, 63, 72, 31, 93, 38, 83, 55, 78, 16, 65, 39, 75, 61, 92, 51, 81, 62, 81, 24, 79, 21, 80, 20, 77, 38, 72, 55, 83, 24, 95, 49, 76, 21, 90, 57, 67, 22, 80, 42, 81, 45, 81, 29, 78, 52, 68, 50, 88, 19, 76, 61, 93, 45, 83, 63, 72, 61, 77, 27, 79, 21, 96, 33, 78, 46, 83, 55, 82, 14, 90, 17, 91, 61, 76, 39, 77, 43, 68, 56, 86, 41, 77, 31, 81, 36, 84, 17, 98, 30, 97, 13, 96, 26, 90, 29, 88, 13, 69, 25, 82, 24, 66, 29, 68, 24, 79, 45, 86, 33, 78, 41, 95, 22, 65, 34, 67, 42, 86, 35, 98, 57, 83, 33, 66, 44, 94, 57, 84, 64, 83, 44, 66, 52, 91, 26, 67, 54, 92, 34, 87, 15, 68, 18, 88, 45, 92, 30, 94, 44, 92, 26, 90, 28, 99, 34, 90, 49, 92, 14, 90, 61, 66, 50, 97, 37, 75, 17, 71, 53, 87, 46, 86, 48, 72, 18, 86, 39, 82, 64, 100, 59, 65, 45, 91, 41, 72, 63, 84, 41, 84, 60, 87, 36, 67, 27, 68, 25, 91, 63, 66, 39, 72, 27, 93, 29, 96, 27, 80, 17, 72, 52, 67, 22, 82, 55, 76, 22, 99, 50, 99, 30, 74, 30, 96, 64, 67, 42, 68, 13, 77, 50, 65, 38, 75, 63, 77, 61, 70, 26, 100, 48, 68, 43, 85, 46, 100, 53, 93, 51, 69, 26, 80, 53, 89, 57, 83, 39, 88, 39, 71, 20, 87, 43, 100, 51, 69, 38, 99, 27, 70, 53, 79, 55, 83, 31, 92, 61, 87, 38, 88, 50, 73, 22, 83, 13, 90, 54, 94, 28, 100, 43, 88, 22, 94, 59, 86, 43, 70, 47, 82, 22, 76, 56, 89, 45, 100, 55, 73, 62, 95, 54, 71, 26, 76, 58, 93, 45, 90, 52, 89, 15, 72, 46, 82, 48, 81, 41, 70, 29, 82, 63, 78, 22, 88, 60, 90, 22, 88, 41, 85, 35, 81, 52, 98, 48, 71, 44, 65, 42, 100, 32, 77, 31, 88, 32, 97, 56, 69, 39, 96, 46, 79, 30, 77, 45, 88, 34, 96, 42, 80, 48, 72, 36, 70, 50, 77, 52, 89, 30, 86, 57, 79, 45, 73, 14, 71, 42, 70, 21, 87, 32, 75, 20, 99, 21, 87, 44, 94, 37, 71, 39, 74, 41, 87, 50, 82, 16, 77, 26, 68, 13, 65, 29, 72, 48, 82, 24, 84, 52, 80, 61, 86, 28, 96, 13, 83, 16, 87, 26, 71, 26, 77, 20, 81, 14, 89, 43, 91, 29, 83, 54, 71, 60, 87, 14, 83, 28, 75, 56, 96, 27, 98, 25, 77, 30, 92, 40, 81, 32, 95, 38, 71, 58, 99, 52, 79, 26, 84, 62, 89, 43, 89, 50, 70, 64, 68, 56, 95, 25, 70, 64, 99, 32, 68, 52, 70, 19, 70, 40, 96, 57, 67, 36, 98, 54, 82, 56, 88, 56, 73, 35, 84, 22, 93, 30, 78, 54, 65, 13, 76, 55, 74, 29, 91, 49, 92, 49, 77, 16, 65, 56, 80, 37, 97, 59, 82, 41, 66, 37, 68, 50, 67, 34, 81, 46, 76, 14, 96, 24, 77, 28, 69, 18, 97, 16, 86, 14, 76, 14, 97, 59, 92, 46, 96, 64, 93, 64, 100, 16, 96, 15, 94, 29, 78, 24, 90, 15, 98, 36, 65, 43, 75, 62, 85, 38, 72, 19, 81, 21, 87, 32, 73, 22, 85, 38, 99, 64, 80, 50, 78, 60, 96, 56, 73, 37, 81, 43, 78, 34, 72, 61, 68, 63, 73, 40, 95, 36, 98, 59, 68, 40, 94, 37, 92, 55, 97, 46, 99, 54, 74, 23, 77, 52, 79, 31, 88, 13, 98, 43, 78, 39, 85, 58, 94, 61, 75, 29, 96, 16, 67, 37, 92, 62, 89, 56, 81, 52, 67, 45, 89, 26, 98, 13, 94, 42, 82, 52, 85, 15, 91, 56, 68, 13, 100, 37, 83, 20, 91, 56, 70, 49, 67, 38, 97, 35, 100, 32, 88, 47, 89, 44, 68, 39, 86, 43, 77, 48, 78, 25, 83, 49, 91, 17, 81, 59, 90, 20, 85, 51, 75, 56, 73, 57, 69, 33, 96, 15, 93, 41, 80, 21, 70, 43, 76, 28, 65, 48, 72, 29, 87, 39, 75, 59, 88, 41, 90, 48, 91, 54, 79, 26, 80, 21, 93, 48, 90, 27, 94, 46, 67, 51, 99, 38, 75, 49, 65, 62, 66, 40, 66, 42, 84, 41, 95, 20, 72, 50, 68, 41, 77, 37, 91, 63, 74, 23, 83, 23, 100, 42, 75, 54, 94, 14, 75, 38, 81, 17, 93, 21, 90, 15, 87, 14, 99, 24, 88, 35, 90, 17, 91, 53, 81, 28, 90, 14, 79, 18, 86, 30, 94, 17, 72, 37, 84, 54, 82, 20, 100, 51, 79, 32, 97, 38, 70, 21, 80, 23, 77, 42, 67, 29, 66, 44, 92, 60, 73, 45, 96, 37, 89, 44, 74, 28, 86, 60, 73, 25, 86, 23, 84, 13, 81, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "print(train_samples)\n",
    "# for i in train_samples:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "# for i in train_labels:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 65 39 ... 81 64 81]\n",
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert both lists into numpy arrays \n",
    "# https://stackoverflow.com/questions/993984/what-are-the-advantages-of-numpy-over-regular-python-lists\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "#train_labels,train_samples=shuffle(train_labels,train_samples)\n",
    "print(train_samples)\n",
    "print(train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 6]\n",
      "(5,)\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [5]\n",
      " [6]]\n",
      "(5, 1)\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[5]\n",
      "[6]\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Reshaping tutorial\n",
    "abc = np.array([1,2,3,5,6])\n",
    "print(abc)\n",
    "print(abc.shape)\n",
    "print(abc.reshape(-1,1))\n",
    "print(abc.reshape(-1,1).shape)\n",
    "\n",
    "for i in abc.reshape(-1,1):\n",
    "    print(i)\n",
    "    \n",
    "for i in abc:\n",
    "    print(i)\n",
    "    \n",
    "#Syntax\n",
    "#reshape(blocks,rows,columns), or reshape(rows,columns)\n",
    "#reshape(-1,1) : -1 to create as many rows as in the original array, 1 means i need 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03448276]\n",
      " [0.59770115]\n",
      " [0.29885057]\n",
      " ...\n",
      " [0.7816092 ]\n",
      " [0.5862069 ]\n",
      " [0.7816092 ]]\n"
     ]
    }
   ],
   "source": [
    "#use sclar object to reshape fit transofrm the input vals to 0-1 form\n",
    "#reshape because the function acceepts 2Dimenationsl input\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))  \n",
    "print(scaled_train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical Device Code here, refer 21:36 in https://www.youtube.com/watch?v=qFJeN9V1ZsI&t=3990s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#relu activation function -  output the input directly if it is positive, otherwise, it will output zero\n",
    "#softmax - Specifically, the network is configured to output N values, one for each class in the classification task, and the softmax function is used to normalize the outputs, converting them from weighted sum values into probabilities that sum to one. Each value in the output of the softmax function is interpreted as the probability of membership for each class.\n",
    "#shape (1,)\n",
    "#Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adam -Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data\n",
    "# sparse_categorical_crossentropy - The lose function that we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03448276]\n",
      " [0.59770115]\n",
      " [0.29885057]\n",
      " ...\n",
      " [0.7816092 ]\n",
      " [0.5862069 ]\n",
      " [0.7816092 ]]\n",
      "[1 0 1 ... 1 0 1]\n",
      "Epoch 1/20\n",
      "210/210 - 0s - loss: 0.2237 - accuracy: 0.9457\n",
      "Epoch 2/20\n",
      "210/210 - 0s - loss: 0.2234 - accuracy: 0.9514\n",
      "Epoch 3/20\n",
      "210/210 - 0s - loss: 0.2234 - accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "210/210 - 0s - loss: 0.2233 - accuracy: 0.9514\n",
      "Epoch 5/20\n",
      "210/210 - 0s - loss: 0.2229 - accuracy: 0.9429\n",
      "Epoch 6/20\n",
      "210/210 - 0s - loss: 0.2230 - accuracy: 0.9495\n",
      "Epoch 7/20\n",
      "210/210 - 0s - loss: 0.2227 - accuracy: 0.9471\n",
      "Epoch 8/20\n",
      "210/210 - 0s - loss: 0.2226 - accuracy: 0.9514\n",
      "Epoch 9/20\n",
      "210/210 - 0s - loss: 0.2226 - accuracy: 0.9457\n",
      "Epoch 10/20\n",
      "210/210 - 0s - loss: 0.2224 - accuracy: 0.9514\n",
      "Epoch 11/20\n",
      "210/210 - 0s - loss: 0.2222 - accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "210/210 - 0s - loss: 0.2221 - accuracy: 0.9510\n",
      "Epoch 13/20\n",
      "210/210 - 0s - loss: 0.2219 - accuracy: 0.9467\n",
      "Epoch 14/20\n",
      "210/210 - 0s - loss: 0.2218 - accuracy: 0.9524\n",
      "Epoch 15/20\n",
      "210/210 - 0s - loss: 0.2216 - accuracy: 0.9495\n",
      "Epoch 16/20\n",
      "210/210 - 0s - loss: 0.2216 - accuracy: 0.9476\n",
      "Epoch 17/20\n",
      "210/210 - 0s - loss: 0.2214 - accuracy: 0.9524\n",
      "Epoch 18/20\n",
      "210/210 - 0s - loss: 0.2215 - accuracy: 0.9457\n",
      "Epoch 19/20\n",
      "210/210 - 0s - loss: 0.2212 - accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "210/210 - 0s - loss: 0.2212 - accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d287d3ce20>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scaled_train_samples) # note that this is 2d\n",
    "print(train_labels) # and this is 1d\n",
    "\n",
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)\n",
    "\n",
    "#with validatin set (note that here the validation split it taken before the shuffle)\n",
    "#model.fit(scaled_train_samples, train_labels,validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save functions saves:\n",
    "- The architecture of the model, allowing to re-create the model.\n",
    "- The weights of the model.\n",
    "- The training configuration (loss, optimizer).\n",
    "- The state of the optimizer, allowing to resume training exactly where you left off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5561034 ,  0.34141016,  0.6794863 , -0.5514803 ,  0.4604888 ,\n",
       "          0.15333319, -0.2410169 , -0.2560547 , -0.53846115,  0.43478328,\n",
       "          0.4520424 , -0.3190799 ,  0.35396117,  0.57932633, -0.5488652 ,\n",
       "          0.70101833]], dtype=float32),\n",
       " array([-0.20439675, -0.17464626, -0.255359  ,  0.        , -0.23310092,\n",
       "         0.20712724,  0.        ,  0.        ,  0.        , -0.22010015,\n",
       "        -0.22909038,  0.        , -0.17924239,  0.20596308,  0.        ,\n",
       "        -0.23991583], dtype=float32),\n",
       " array([[-4.37281132e-02,  1.95367172e-01, -2.22632185e-01,\n",
       "          1.05354816e-01, -2.33667016e-01, -2.61804938e-01,\n",
       "         -1.86254844e-01,  6.37187958e-02,  2.97886461e-01,\n",
       "          2.39527181e-01, -2.51901001e-01,  3.03705513e-01,\n",
       "          2.62788802e-01, -2.77882338e-01,  2.61186033e-01,\n",
       "         -2.24625930e-01, -2.61573970e-01,  6.63847625e-01,\n",
       "          3.58521610e-01, -2.92054147e-01, -4.21086758e-01,\n",
       "         -3.72107238e-01,  1.32070988e-01, -3.93300712e-01,\n",
       "         -3.25761914e-01,  5.96267462e-01, -4.34247673e-01,\n",
       "         -1.89157933e-01,  6.06462240e-01, -2.17203006e-01,\n",
       "          1.10701047e-01, -2.71352351e-01],\n",
       "        [ 2.63745934e-01, -8.30587745e-03, -4.43204403e-01,\n",
       "         -1.57466441e-01, -4.38118488e-01,  2.48503968e-01,\n",
       "         -6.71103477e-01, -7.68110156e-03, -1.07315227e-01,\n",
       "         -2.20313370e-02, -3.29233378e-01,  5.87835908e-01,\n",
       "          7.64010251e-02, -3.01112384e-01, -1.66460127e-01,\n",
       "         -8.32835138e-01, -9.02656913e-01,  1.68342054e-01,\n",
       "          7.28757739e-01, -3.99925143e-01, -6.12755001e-01,\n",
       "         -1.10456116e-01, -1.96610689e-02, -9.18916941e-01,\n",
       "         -2.64428318e-01,  5.44191189e-02, -8.86433244e-01,\n",
       "          1.01611912e-02,  1.75393194e-01, -6.82265460e-02,\n",
       "         -6.51055694e-01,  4.64484394e-02],\n",
       "        [-1.97411120e-01, -3.25775743e-01, -5.23516595e-01,\n",
       "          1.21973902e-01, -6.81847155e-01,  2.72070765e-01,\n",
       "         -1.32216126e-01,  2.52215654e-01,  1.48499280e-01,\n",
       "         -2.14552879e-02, -9.69106779e-02,  3.19896281e-01,\n",
       "          5.11280894e-02, -4.92904574e-01,  3.26822132e-01,\n",
       "         -4.75148022e-01, -5.13122082e-01,  5.86954474e-01,\n",
       "          3.65931988e-01, -1.69759706e-01, -4.24857855e-01,\n",
       "          3.05381030e-01,  2.71626562e-01, -1.24794252e-01,\n",
       "          2.29734272e-01,  8.01979750e-02, -2.75773997e-03,\n",
       "         -3.35938811e-01,  5.97207904e-01, -1.37197852e-01,\n",
       "         -4.51987356e-01, -3.26084763e-01],\n",
       "        [-6.39780760e-02, -3.06136578e-01, -3.28024447e-01,\n",
       "          1.07879162e-01,  2.34272987e-01, -3.44658196e-01,\n",
       "          1.30011827e-01, -3.44699860e-01,  1.64243549e-01,\n",
       "          1.32331818e-01,  2.27482051e-01,  2.20571846e-01,\n",
       "         -1.91577658e-01,  2.79165357e-01, -5.91246188e-02,\n",
       "          3.62296700e-02, -2.58197576e-01, -1.52542174e-01,\n",
       "         -1.22622713e-01, -1.39243156e-01,  2.76887745e-01,\n",
       "          2.02873856e-01,  1.12836808e-01, -1.45998120e-01,\n",
       "          1.46046251e-01, -2.32689545e-01,  3.41731608e-02,\n",
       "         -2.19683453e-01, -2.18295306e-01, -2.47895539e-01,\n",
       "          1.64079368e-02,  2.22091109e-01],\n",
       "        [-7.45667815e-02,  3.37545238e-02, -2.61509091e-01,\n",
       "          3.11869591e-01, -7.73903370e-01, -3.76915723e-01,\n",
       "         -5.51067352e-01, -2.16443583e-01,  2.41421133e-01,\n",
       "         -8.68439972e-02, -6.57539427e-01,  1.34926721e-01,\n",
       "         -1.41533583e-01, -6.94749355e-01, -1.84922114e-01,\n",
       "         -1.15879595e-01, -3.56068164e-01,  4.90185767e-01,\n",
       "          7.23688781e-01, -4.28684682e-01, -6.68185413e-01,\n",
       "          2.61687100e-01, -3.38268340e-01, -7.16066182e-01,\n",
       "          2.25206524e-01,  3.59476000e-01, -3.74275744e-01,\n",
       "          2.20386863e-01,  2.45276000e-02, -3.11791092e-01,\n",
       "         -2.10771993e-01, -1.14153177e-01],\n",
       "        [ 4.52066362e-02, -1.05452046e-01,  4.57990915e-02,\n",
       "         -1.61826953e-01,  2.27086365e-01,  1.10808434e-03,\n",
       "          1.97903663e-01,  2.23791480e-01,  2.72308677e-01,\n",
       "         -3.34239244e-01,  3.20551753e-01, -2.39090383e-01,\n",
       "         -2.06809774e-01,  4.40311342e-01, -8.71123224e-02,\n",
       "         -1.45682218e-02,  1.50536597e-01, -1.94294885e-01,\n",
       "         -2.01562345e-02,  4.02608603e-01,  3.22812110e-01,\n",
       "          9.03717428e-02, -3.49035859e-03,  1.55392617e-01,\n",
       "          1.31800443e-01,  4.73535582e-02,  2.69736230e-01,\n",
       "          7.68371969e-02,  3.89170915e-01, -1.87878013e-02,\n",
       "          8.23696330e-02, -2.92017549e-01],\n",
       "        [ 2.86360830e-01, -2.49180585e-01, -1.38662457e-01,\n",
       "         -9.97104943e-02,  2.70216078e-01,  3.42927307e-01,\n",
       "         -1.46563053e-01,  1.43545002e-01,  4.44048941e-02,\n",
       "         -1.05683640e-01,  1.23997539e-01, -9.54788923e-02,\n",
       "         -2.88684428e-01,  5.09589911e-03,  7.79365897e-02,\n",
       "         -1.40097633e-01, -3.04513752e-01,  1.74662381e-01,\n",
       "         -1.39050454e-01, -3.04793537e-01,  2.61257261e-01,\n",
       "          2.91298538e-01, -1.68814063e-01,  2.02829033e-01,\n",
       "         -2.39952296e-01, -1.57135129e-02, -6.45408034e-02,\n",
       "         -2.89295375e-01,  1.10388070e-01,  1.65261835e-01,\n",
       "         -3.10487986e-01,  9.18431282e-02],\n",
       "        [-2.73712158e-01,  1.18942708e-01, -1.82600036e-01,\n",
       "         -8.14577937e-02, -1.15998983e-02,  1.02333397e-01,\n",
       "          2.52970427e-01, -2.83448845e-01, -2.61732638e-02,\n",
       "          6.28629625e-02, -3.17836463e-01,  7.45073557e-02,\n",
       "          1.88148230e-01,  9.01768804e-02,  9.38123167e-02,\n",
       "         -1.74130961e-01, -2.67172933e-01,  2.92107731e-01,\n",
       "         -2.20620960e-01, -3.45147282e-01, -1.99818313e-02,\n",
       "         -1.20000422e-01, -2.96923518e-03, -1.69667527e-01,\n",
       "          3.36141080e-01,  2.19629079e-01,  3.24874550e-01,\n",
       "          3.00223827e-02,  3.53245646e-01, -1.24652848e-01,\n",
       "          3.57108414e-02, -1.82844996e-01],\n",
       "        [-1.82514220e-01, -7.61063397e-02, -1.44768432e-01,\n",
       "         -3.49737108e-02, -2.08069205e-01, -1.92063436e-01,\n",
       "          1.18908733e-01, -5.46250939e-02, -1.46999359e-01,\n",
       "          1.22917324e-01,  3.25345248e-01, -3.39199603e-01,\n",
       "         -4.50466275e-02,  1.75097555e-01,  2.58201092e-01,\n",
       "         -3.38597238e-01,  1.44166231e-01,  3.32687169e-01,\n",
       "         -1.08835548e-01, -1.32655606e-01, -7.86238611e-02,\n",
       "         -2.53245234e-02, -2.66311944e-01, -1.96532264e-01,\n",
       "         -3.51289928e-01, -1.93877518e-01,  4.89027202e-02,\n",
       "         -2.89950579e-01,  2.63767034e-01, -2.54239470e-01,\n",
       "          1.39281183e-01,  9.98485088e-02],\n",
       "        [ 4.98228073e-02, -3.01775813e-01, -6.15373969e-01,\n",
       "          5.48935831e-02, -3.01742703e-01,  9.40070972e-02,\n",
       "         -4.58071649e-01,  2.47775942e-01, -3.02984565e-01,\n",
       "         -2.79958516e-01, -6.64532781e-01,  4.51376528e-01,\n",
       "          3.02405894e-01, -4.02265579e-01, -3.35332938e-02,\n",
       "         -3.06619912e-01, -6.76940501e-01,  7.31545269e-01,\n",
       "          4.81496274e-01, -4.53035593e-01, -4.94163930e-01,\n",
       "         -1.73874423e-01,  2.35034928e-01, -6.85384035e-01,\n",
       "         -1.49940446e-01,  1.93304747e-01, -5.99238276e-01,\n",
       "          2.44591072e-01,  6.42674863e-01,  3.18751335e-01,\n",
       "         -5.82855821e-01, -3.32359195e-01],\n",
       "        [-5.10447323e-02, -1.77517638e-01, -8.73203158e-01,\n",
       "         -3.41834456e-01, -3.52289289e-01, -1.60943344e-01,\n",
       "         -2.66393095e-01, -3.37799579e-01, -1.14917181e-01,\n",
       "          2.88368493e-01, -4.81440216e-01,  3.96234095e-01,\n",
       "         -2.18843803e-01, -6.82565331e-01,  1.05572842e-01,\n",
       "         -8.21774065e-01, -4.57676739e-01,  2.74704963e-01,\n",
       "          4.09604400e-01, -5.16629219e-01, -7.84846306e-01,\n",
       "         -2.28656098e-01, -2.15121701e-01, -2.00737834e-01,\n",
       "          2.64337271e-01,  5.48280835e-01, -8.60613167e-01,\n",
       "         -2.77337462e-01,  6.08168066e-01,  3.19948137e-01,\n",
       "         -4.90933508e-01,  2.11483970e-01],\n",
       "        [ 2.85190672e-01,  1.68296725e-01,  3.08419079e-01,\n",
       "          3.32356364e-01, -1.43765762e-01,  3.25522810e-01,\n",
       "          3.25275570e-01,  1.32850587e-01, -2.05404177e-01,\n",
       "          8.80163610e-02,  3.02450508e-01,  1.55693382e-01,\n",
       "         -1.72228873e-01,  2.88511544e-01, -1.72624379e-01,\n",
       "          1.23545229e-01,  1.80206329e-01,  2.79703110e-01,\n",
       "         -5.80679774e-02, -3.53474408e-01, -3.46888900e-02,\n",
       "         -1.63356036e-01, -2.47148871e-01,  3.32328469e-01,\n",
       "         -1.84551105e-01, -6.19751811e-02,  3.02288264e-01,\n",
       "          8.30709934e-04,  7.22365677e-02,  2.41708368e-01,\n",
       "          3.50952476e-01,  2.21158594e-01],\n",
       "        [-3.28157216e-01, -2.93001831e-01, -5.90839624e-01,\n",
       "          6.01739883e-02, -2.47157753e-01,  1.76746011e-01,\n",
       "         -4.29991037e-01, -1.89805031e-02,  1.94355875e-01,\n",
       "         -3.16427916e-01, -5.59971929e-01,  3.41255724e-01,\n",
       "          1.78997174e-01, -4.41199809e-01,  1.75284728e-01,\n",
       "         -5.86054862e-01, -2.35086799e-01,  4.11024302e-01,\n",
       "          2.30910629e-01, -1.95094451e-01, -4.78611261e-01,\n",
       "         -1.76716104e-01, -1.58486396e-01, -4.73503172e-01,\n",
       "          8.05867910e-02,  5.37399471e-01, -8.34014535e-01,\n",
       "          1.47243127e-01,  6.70786977e-01,  2.28156850e-01,\n",
       "         -3.77632856e-01,  2.91286916e-01],\n",
       "        [-2.92922288e-01,  1.12777106e-01,  2.35714167e-01,\n",
       "         -2.92135745e-01,  1.19250186e-01, -8.01895186e-02,\n",
       "          6.70872107e-02, -1.63354978e-01, -3.17857444e-01,\n",
       "         -1.63508102e-01,  7.63630345e-02,  3.96033108e-01,\n",
       "         -2.27438882e-01,  1.29463851e-01, -2.54843652e-01,\n",
       "          1.81164309e-01,  3.01812023e-01,  7.66406879e-02,\n",
       "          1.37274176e-01, -7.98620209e-02,  3.01345468e-01,\n",
       "         -2.23060831e-01, -1.98603615e-01,  2.04893857e-01,\n",
       "         -2.87065297e-01,  2.04539090e-01, -2.88667176e-02,\n",
       "          2.04140916e-02, -7.52952648e-03, -1.12692997e-01,\n",
       "          4.73938920e-02,  1.22982979e-01],\n",
       "        [ 3.49676698e-01, -1.85236663e-01,  2.27203697e-01,\n",
       "          1.71572059e-01, -9.65790749e-02, -5.31770289e-02,\n",
       "         -3.04212153e-01, -3.12638223e-01,  9.04793441e-02,\n",
       "         -5.79010844e-02,  1.14029646e-01,  1.85667306e-01,\n",
       "          2.95354992e-01,  1.80573195e-01, -1.90077141e-01,\n",
       "          2.21699089e-01,  9.40811336e-02, -5.94329834e-03,\n",
       "         -2.10170403e-01,  3.32738429e-01, -2.06167713e-01,\n",
       "          6.80713654e-02, -9.60286558e-02, -1.73973083e-01,\n",
       "          2.12091535e-01,  3.48304182e-01,  7.67605305e-02,\n",
       "         -6.25193119e-04, -2.08354548e-01,  7.42577016e-02,\n",
       "          6.14927709e-02, -1.87208623e-01],\n",
       "        [-2.06995219e-01, -2.79481173e-01, -1.50429621e-01,\n",
       "         -1.43120334e-01, -6.50579989e-01,  1.60732672e-01,\n",
       "         -2.35928848e-01, -1.69324115e-01, -2.11546749e-01,\n",
       "         -2.60690629e-01, -1.69413403e-01,  3.24953079e-01,\n",
       "         -2.99224734e-01, -5.17715514e-01, -3.56053412e-02,\n",
       "         -1.18557625e-01, -5.79618633e-01,  3.04427266e-01,\n",
       "          6.58138454e-01, -4.08312708e-01, -5.42092383e-01,\n",
       "          3.18168730e-01, -3.13792646e-01, -3.19745392e-01,\n",
       "         -2.71261156e-01,  3.84808987e-01,  3.55597213e-02,\n",
       "         -3.38997990e-01,  3.89047712e-01, -2.77138799e-01,\n",
       "          3.99005115e-02,  2.55194068e-01]], dtype=float32),\n",
       " array([ 0.        , -0.01840496,  0.16219509,  0.        ,  0.05313036,\n",
       "        -0.00957943,  0.1236328 , -0.01509669, -0.00055565, -0.0005123 ,\n",
       "         0.09471669, -0.11536436, -0.00055579,  0.19823661, -0.00680117,\n",
       "         0.18135476,  0.19651026, -0.10787142, -0.1319883 ,  0.19227327,\n",
       "         0.18315287, -0.00173557, -0.00051244,  0.14357872,  0.        ,\n",
       "        -0.11138222,  0.17949909, -0.0308631 , -0.12373593, -0.00055584,\n",
       "         0.11919981, -0.00255823], dtype=float32),\n",
       " array([[ 0.3119584 , -0.15294027],\n",
       "        [-0.12830965, -0.09069611],\n",
       "        [ 0.25815678, -0.8033679 ],\n",
       "        [ 0.34393725, -0.40945128],\n",
       "        [-0.56186247,  0.39317903],\n",
       "        [ 0.0424671 , -0.16535522],\n",
       "        [ 0.47726935, -0.5780658 ],\n",
       "        [-0.11648785, -0.0582375 ],\n",
       "        [-0.01495606,  0.12991022],\n",
       "        [ 0.1388671 ,  0.23681276],\n",
       "        [ 0.16758291, -0.7914837 ],\n",
       "        [-0.6773756 ,  0.30720383],\n",
       "        [-0.29752478,  0.05957681],\n",
       "        [ 0.81640583, -0.39924794],\n",
       "        [-0.01609371, -0.20916948],\n",
       "        [ 0.7703146 , -0.671691  ],\n",
       "        [ 0.3401121 , -0.8386894 ],\n",
       "        [-0.18933974,  0.7481358 ],\n",
       "        [-0.41155076,  0.28704113],\n",
       "        [ 0.8587    , -0.679114  ],\n",
       "        [ 0.7926004 , -0.5734842 ],\n",
       "        [ 0.04462869, -0.16007842],\n",
       "        [ 0.12203648,  0.29843518],\n",
       "        [ 0.59851325, -0.41580585],\n",
       "        [-0.10794625, -0.28536722],\n",
       "        [-0.7620921 ,  0.5929129 ],\n",
       "        [ 0.7478031 , -0.4783562 ],\n",
       "        [-0.1676359 ,  0.17518331],\n",
       "        [-0.67644614,  0.45106977],\n",
       "        [-0.306995  ,  0.40647072],\n",
       "        [ 0.20074783, -0.46957564],\n",
       "        [-0.38518405, -0.25512996]], dtype=float32),\n",
       " array([ 0.01094792, -0.01094792], dtype=float32)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1d287cc2760>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the architecture of a model, and not its weights or its training configuration, you can use the following function to save the architecture only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "# from keras.models import model_from_json\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)\n",
    "\n",
    "# model reconstruction from YAML\n",
    "# from keras.models import model_from_yaml\n",
    "# model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. model.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the weights of a model, you can use the following function save the weights only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels =  []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 2)\n",
      "[[0.84198374 0.15801626]\n",
      " [0.07142837 0.9285716 ]\n",
      " [0.66478455 0.33521542]\n",
      " ...\n",
      " [0.07853193 0.92146814]\n",
      " [0.96740294 0.03259704]\n",
      " [0.04404931 0.95595074]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape) # notice for each sample two columns\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-106-8bcbc52007da>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840,)\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(rounded_predictions.shape) # notice the shape difference, 0 if first val big, 1 if second big\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[400  20]\n",
      " [ 20 400]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAEmCAYAAAAuryiLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyyklEQVR4nO3dd5hV1fX/8fdnABHp3RFFLCgoCiiKWMGKFXsDCzGxRKOJotFoxBITaxR7iVGavQAq9oY9gBQpFr5BfwoIUkRQJJT1+2PvwZPJzJ077TbWy+c83Hvqmiuz2HefffaSmeGcc672FWU7AOecW194wnXOuQzxhOuccxniCdc55zLEE65zzmWIJ1znnMsQT7gu70hqIOk5SUslPVmN8/SX9EpNxpYNkl6UdFq243AV84Trao2kkyVNkLRc0ryYGPasgVMfC7QFWprZcVU9iZmNNLMDayCe/yKptyST9Gyp9V3j+rfSPM9VkkZUtJ+ZHWxmQ6sYrssgT7iuVki6ELgN+CshObYH7gb61cDpNwc+N7PVNXCu2vId0EtSy8S604DPa+oCCvx3OJ+YmS++1OgCNAWWA8el2Kc+ISHPjcttQP24rTfwDXARsACYBwyM264G/gOsitc4A7gKGJE4dwfAgLrx/enAv4FlwGygf2L9u4njdgfGA0vjn7sntr0FXAu8F8/zCtCqnJ+tJP57gXPjujrAHOBK4K3EvkOAr4EfgInAXnF931I/55REHNfFOFYAW8d1v47b7wGeTpz/BuB1QNn+e+GLeQvX1YpewIbAsyn2uRzYDegGdAV2Ba5IbN+YkLjbEZLqXZKam9lgQqv5cTNrZGYPpgpEUkPgduBgM2tMSKqTy9ivBfBC3Lcl8HfghVIt1JOBgUAbYANgUKprA8OAU+Prg4BphH9cksYTPoMWwCPAk5I2NLOXSv2cXRPHnAKcCTQGvip1vouAHSSdLmkvwmd3msXs67LLE66rDS2BhZb6K39/4BozW2Bm3xFarqcktq+K21eZ2VhCK2/bKsazFugiqYGZzTOz6WXscyjwhZkNN7PVZvYo8ClweGKfh8zsczNbATxBSJTlMrP3gRaStiUk3mFl7DPCzBbFa95CaPlX9HM+bGbT4zGrSp3vJ8Ln+HdgBPA7M/umgvO5DPGE62rDIqCVpLop9tmE/26dfRXXrTtHqYT9E9CosoGY2Y/ACcDZwDxJL0jqlEY8JTG1S7z/tgrxDAfOA/pQRotf0iBJM+OIi+8JrfpWFZzz61QbzewjQheKCP8wuBzhCdfVhg+AlcCRKfaZS7j5VaI9//t1O10/Ahsl3m+c3GhmL5vZAUAxodX6QBrxlMQ0p4oxlRgO/BYYG1uf68Sv/JcAxwPNzawZof9YJaGXc86U3QOSziW0lOfG87sc4QnX1TgzW0q4OXSXpCMlbSSpnqSDJd0Yd3sUuEJSa0mt4v4VDoEqx2Rgb0ntJTUFLivZIKmtpH6xL3cloWtibRnnGAtsE4ey1ZV0ArAd8HwVYwLAzGYD+xD6rEtrDKwmjGioK+lKoEli+3ygQ2VGIkjaBvgLMIDQtXCJpG5Vi97VNE+4rlbE/sgLCTfCviN8DT4PGBV3+QswAZgKfAJ8HNdV5VqvAo/Hc03kv5NkUYxjLrCYkPzOKeMci4DDCDedFhFahoeZ2cKqxFTq3O+aWVmt95eBlwhDxb4Cfua/uwtKHupYJOnjiq4Tu3BGADeY2RQz+wL4EzBcUv3q/AyuZshvXjrnXGZ4C9c55zLEE65zziVIqiNpkqTn4/stJH0kaZakxyVtENfXj+9nxe0dKjq3J1znnPtvFwAzE+9vAG41s62BJYSHSYh/Lonrb437peQJ1znnIkmbEh6C+Ud8L2Bf4Km4y1B+Ge7YL74nbt8v7l+uVAPTXR5Q3QamDRpnO4yC1b1z+2yHUNC++upLFi5cmDJJpatOk83NVq9IuY+t+G46YTRIifvN7P7E+9sII1RKfqlaAt8nHsL5hl8ehmlHHFViZqslLY37lzuyxRNuntMGjam/7fHZDqNgvffRndkOoaDt0bNHjZ3LVq+o8Hfh58l3/WxmZV5U0mHAAjObKKl3jQWW4AnXOVcYJCiqU50z7AEcIekQwuRLTQizuTWTVDe2cjfll6cP5wCbAd/EMdBNCWO4y+V9uM65wqGi1EsKZnaZmW1qZh2AE4E3zKw/8CZh0nsIcxqPjq/HxPfE7W9UNCubJ1znXIGILdxUS9X8EbhQ0ixCH23JlKAPAi3j+guBSys6kXcpOOcKR+pBAmkzs7cIE7tjZv8mzNdcep+fgUqVePKE65wrDNXvw611nnCdc4Ujx0u8ecJ1zhUIb+E651xmiBrrw60tnnCdc4XDuxSccy4TBHW8S8E552qf8Bauc85lht80c865zPGbZs45lwH+4INzzmWQ9+E651wmeAvXOecyx/twnXMuA/JgWFhuR+ecc2mr3ny4kjaU9C9JUyRNl3R1XP+wpNmSJselW1wvSbfHMulTJe1UUYTewnXOFY7qtXBXAvua2XJJ9YB3Jb0Yt11sZk+V2v9goGNcegL3xD/L5QnXOVcYqjksLJbHWR7f1otLqpI5/YBh8bgPJTWTVGxm88o7wLsUnHOFQ0q9VHi46kiaDCwAXjWzj+Km62K3wa2S6sd168qkR8kS6mXyhOucKwgCioqKUi5AK0kTEsuZyXOY2Roz60aozrurpC7AZUAnYBegBaHGWZV4l4JzrjAoLqktNLMeFe1kZt9LehPoa2Y3x9UrJT0EDIrvS8qkl0iWUC+Tt3CdcwVC6bRwyz9aai2pWXzdADgA+FRScVwn4EhgWjxkDHBqHK2wG7A0Vf8teAvXOVdAVL0HH4qBoZLqEBqjT5jZ85LekNSa0H6eDJwd9x8LHALMAn4CBlZ0AU+4zrnCIFBR1ROumU0Fupexft9y9jfg3MpcwxOuc64gCFW3hVvrPOE65wqGJ1znnMuQim6MZZsnXOdcYUhvWFhWecJ1zhUExWFhucwTrnOuYHgfrnPOZUI1h4Vlgidc51zByPUWbm53eLi8VFQkPnj0jzw9JDyQs/kmLRk3bBDTRg9m+PUDqVc3TKG3Qb26DL9+INNGD2bcsEG0L26RzbDzztdff81B+/eh+47bsVPX7bnz9iEALF68mEP7HkCXzh05tO8BLFmyJMuRZoaq+WhvJmQ/Aldwzju5D5/Nnr/u/XUX9OOOkW/Spd/VLFm2gtOP6gXA6Uf2YsmyFXTpdzV3jHyT6y7ol62Q81LdunW5/sZbmDR1Bm+/+yH33XsXM2fM4OYbr6f3vvsxbeYX9N53P26+8fpsh5o5qmDJMk+4rka1a9OMvntuz0PPvr9u3T67bMMzr00CYORzH3F4764AHNZ7R0Y+F6Ybfea1SfTeddvMB5zHiouL6b5TqOrSuHFjOnXqzNy5c3j+udEMOOU0AAacchrPjRmVxSgzSKFLIdWSbZ5wXY266eJjuHzIKNauDRPlt2zWkKXLVrBmzVoA5sxfwiZtmgKwSZumfPNt+Lq7Zs1afli+gpbNGmYn8Dz31ZdfMnnyJHbZtScL5s+nuLgYgI033pgF8+dXcHTh8C4Ft944eK8uLFi8jEkzv654Z1djli9fzknHH8NNt9xGkyZN/mtbrrTsMibHuxQKapSCpCOA7czsfzqtJC03s0Y1eK3jgGuAb82sj6RHge2Bh8zs1kqcpxlwspndXVOxZUuvblty2D470HfP7am/QT2aNNyQmy8+lqaNG1CnThFr1qylXdvmzF2wFIC5C5ay6cbNmbPge+rUKaJJowYs+v7HLP8U+WXVqlWcdPwxnHBSf4486mgA2rRty7x58yguLmbevHm0btMmy1FmhpT7Dz7kdnSVZGZjykq2teQM4Dcx2W4M7GJmO1Ym2UbNgN/WeHRZcOUdY9i675/pdOhgTr30Id4a/zkDLx/KuAmfc/T+Yda7/of35Pm3pgLwwtuf0P/wUOT06P278/b4z7MWez4yM87+zRls26kzF/zhwnXrDz3sCEYMHwrAiOFDOezw9edmpPfhlkFSB0kzJT0Q67+/IqmBpG6SPozF2p6V1DzFOc6XNCPu+1hcd7qkO+PrLSR9IOkTSX8pdezFksbHY6+uINYBsVb9ZEn3xSJzVwJ7Ag9Kugl4BWgX99lL0laSXpI0UdI7kjrFc7WNP9eUuOwOXA9sFY+9SVKxpHHx/TRJe1Xns84Flw8ZzfkD+jBt9GBaNt2Ih0d9AMDDo96nZdONmDZ6MOcP6MMVt4/OcqT55f333uORkcN5+8036LlzN3ru3I2XXhzLoEsu5Y3XXqVL5468+fprDLrk0myHmjEqUsol5bHShvF3fUrMS1fH9VtI+kjSLEmPS9ogrq8f38+K2ztUGF+YQzezYmCzgB5mNlnSE4RyFZcAvzOztyVdAzQxs9+Xc465wBZmtlJSs1iD6PR4zvMkjQGeMrNhks4FbjCzRpIOBI4FziL06owBbjSzcWVcozNwI3C0ma2SdDfwYTznW8AgM5sQf57nzaxLPO514Gwz+0JST+BvZravpMeBD8zstjirfCOgealjLwI2NLPr4j4bmdmyUnGdCYTid/Ua7bzh9qdV8v+AS9eS8XdmO4SCtkfPHkycOKFGmp7123a0dv2HpNxn9q2HTiyvpplCE7ihmS2XVA94F7gAuBB4xswek3QvMMXM7pH0W2BHMztb0onAUWZ2QqrrZ7NLYbaZTY6vJwJbAc3M7O24biiwd4rjpwIjJQ0AVpexfQ/g0fh6eGL9gXGZBHxMqMbZsZxr7AfsDIxXKJ28H7BlipiQ1AjYHXgyHnMfoXQHwL7APbCuOujSMk4xHhgo6Spgh9LJNh57v5n1MLMeqtsgVTjOrTek8NBNqiUVC5bHt/XiYoTf26fi+qGEumYA/eJ74vb9VEG/RTZvmq1MvF5D6MusjEMJCflw4HJJO5SxT1nNdxFanPelcQ0BQ83sskrEVQR8H0stV5qZjZO0N+Hne1jS381sWFXO5dz6Ja1+2laSJiTe329m9687Q/hWORHYGrgL+D/C73NJo+4boF183Q74GsDMVktaCrQEFpZ38Vy6abYUWJLoszwFeLusHSUVAZuZ2ZuEGvFNCV/Pk94DToyv+yfWvwz8KrZEkdROUnm3cV8Hji3ZLqmFpM1T/RBm9gMwW2EUAwq6Js53TlxfR1JTYBnQOPGzbQ7MN7MHgH8AO6W6nnPuF2m0cBeWfDuMy/3J4+M3z26Ekue7Er4B11x8NXmyGnAacJOkqUA3wrCrstQBRkj6hNA1cLuZfV9qnwuAc+M+Jf8iYWavAI8AH8RtT5FIeElmNgO4AnglxvQqv3QPpNIfOEPSFGA64atHSUx94nUnEoawLQLeizfIbgJ6A1MkTQJOAFJ3SjnnAoVuhVRLumI+eRPoBTSTVNIbsCkwJ76eA2wGELc3BRalDDEbN81czSnaqI3V3/b4bIdRsPymWe2qyZtmDYq3sS0Gpv7/NfNvB6W6adYaWBVvwDcgjD66gdAQfDpx02yqmd0db8bvkLhpdrSZpfxlLKgHH5xz67eKboxVoBgYGvtxi4AnzOx5STOAxxSGl04CHoz7PwgMlzQLWMwvXZjlyvmEK+kuwoiDpCFm9lANXqMloX+1tP3iV37nXK6rZLdBaWY2Fehexvp/E/pzS6//GTiuMtfI+YRrZudm4BqLCH3Gzrk85TXNnHMug3Lg6d2UPOE65wqDqt2HW+s84TrnCoLI/ZpmnnCdcwXDW7jOOZchOd7A9YTrnCsQ8i4F55zLiDAszBOuc85lRI43cD3hOucKhA8Lc865zPBhYc45l0HewnXOuQzxFq5zzmWAlMejFCTdQdk1wQAws/NrJSLnnKui6jRwJW0GDAPaEnLf/WY2JBZ0/Q3wXdz1T2Y2Nh5zGXAGoS7j+Wb2cqprpGrhTkixzTnnck6d6rVwVwMXmdnHkhoDEyW9GrfdamY3J3eWtB1h0vHtgU2A1yRtY2ZryrtAuQnXzIYm30vayMx+quIP4pxztUrVfNLMzOYB8+LrZZJmkqiHWIZ+wGNmtpJQOHYWYaLyD8o7oMLZeiX1iiUmPo3vu0q6O/0fwznnMqNIqRdimfTEcmZZ55HUgVD94aO46jxJUyX9U1LzuG5dmfQoWUK97PjS+BluAw4iVqM0synA3mkc55xzGVXdMukAkhoBTwO/N7MfgHuArQhVYeYBt1Q5vnR2MrOvS60qt4/COeeyQYT5FFL9V+E5pHqEZDvSzJ4BMLP5ZrbGzNYCD/BLfbN1ZdKjZAn1MqWTcL+WtDtgkupJGgTMTOM455zLHIk6RamX1IdLhEq8M83s74n1xYndjgKmxddjgBMl1Ze0BdAR+Feqa6QzDvdsYAihb2Iu8DJQ64UdnXOusqr53MMewCnAJ5Imx3V/Ak6S1I0wVOxL4CwAM5su6QlgBmGEw7mpRihAGgnXzBYC/asWv3POZYao3rAwM3s3nqa0sSmOuQ64Lt1rpDNKYUtJz0n6TtICSaMlbZnuBZxzLlMkpVyyLZ0+3EeAJ4BiwuDeJ4FHazMo55yrLIlq9eFmQjoJdyMzG25mq+MyAtiwtgNzzrnKUgVLtqWaS6FFfPmipEuBxwidxieQok/DOeeyJRe6DVJJddNsIiHBlvwEZyW2GXBZbQXlnHOVJeVGt0EqqeZS2CKTgTjnXHXleAM3vflwJXUBtiPRd2tmw2orKOecq6zqDgvLhAoTrqTBQG9Cwh0LHAy8S5g30jnnckau9+GmM0rhWGA/4FszGwh0BZrWalTOOVdJEtSRUi7Zlk6XwgozWytptaQmwAL+e8IG55zLCTmQU1NKJ+FOkNSMMEvORGA5KSbYdc65bMnbmmYlzOy38eW9kl4CmpjZ1NoNyznnKkeIohxv4qZ68GGnVNvM7OPaCclVRvfO7XnvozuzHUbBar7LedkOoaCt/Oz/1dzJlN8t3FSzmhuwbw3H4pxz1ZJWRYUsSvXgQ59MBuKcc9UhqjcsLEWZ9BbA40AHwny4x5vZkjhh+RDgEOAn4PSKvvnn+j8IzjmXtrpFqZcKlJRJ3w7YDTg3lkK/FHjdzDoCr8f3EJ5J6BiXMwm1z1LyhOucKwglZdKrOh+umc0raaGa2TJCKbF2hHLoQ+NuQ4Ej4+t+wDALPgSalSrH8z/SerTXOefyQZ2Km5CtJE1IvL+/nMq9HfilTHpbM5sXN31L6HKA8sukz6Mc6TzaK0KJnS3N7BpJ7YGNzSxlsTTnnMskQTrDwhaaWY+U5ylVJj3ZMjYzk2RVjTGdLoW7gV7ASfH9MuCuql7QOedqSx2lXipSVpl0YH5JV0H8c0FcXytl0nua2bnAzwBmtgTYII3jnHMuY6Tw4EOqpYLjyyyTTiiHflp8fRowOrH+VAW7AUsTXQ9lSqcPd5WkOoRhEkhqDaxN4zjnnMuoNPpwUymvTPr1wBOSzgC+Ao6P28YShoTNIgwLG1jRBdJJuLcDzwJtJF1HmD3sivR/Buecq31p9uGWK0WZdAgzJpbe34BzK3ONdOZSGClpYryggCPNbGZlLuKcc5mQ41MppDVKoT2hufxccp2Z1eBD0M45V01xPtxclk6Xwgv8UkxyQ2AL4DNg+1qMyznnKiV0KWQ7itTS6VLYIfk+ziL223J2d865rMn7mmalmdnHknrWRjDOOVdVBdHClXRh4m0RsBMwt9Yics65qlBhtHAbJ16vJvTpPl074TjnXNXkfQs3PvDQ2MwGZSge55yrotyozJtKqhI7dc1staQ9MhmQc85VRZiAPNtRpJaqhfsvQn/tZEljgCeBH0s2JiZ2cM657BPUzfE+hXT6cDcEFhFqmJWMxzXAE65zLmfkewu3TRyhMI1fEm2JKs8H6ZxztSVvy6QDdYBGlD2Zgydc51xOEenNeZtNqRLuPDO7JmOROOdcdah6VXszIdXskbkduXPOJYQWrlIuFZ5D+qekBZKmJdZdJWmOpMlxOSSx7TJJsyR9Jumgis6fKuH+z/yPzjmXy1TBkoaHgb5lrL/VzLrFZSxALKF+ImEir77A3fHZhXKVm3DNbHF68TnnXC4QRUWpl4qY2Tgg3dzXD3jMzFaa2WxC5YddUx1QvYIUzjmXI0RIaKmWajhP0tTY5dA8riuvTHq5POE65wpGGkUkW0makFjOTOO09wBbAd2AecAtVY2v0tMzOudcTkpvlMJCM+tRmdOa2fx1l5AeAJ6Pb2ulTLpzzuW82upSkFSceHsU4WEwCGXST5RUX9IWQEfClAjl8hauc65gVPdJM0mPAr0JXQ/fAIOB3pK6ER74+hI4C8DMpkt6AphBmLr2XDNbk+r8nnCdcwWjus89mNlJZax+MMX+1wHXpXt+T7jOuYJQ8uBDLvOE65wrEEI5/oCsJ1znXEHwFq5zzmWKcn8+XB8W5mrF119/zUH796H7jtuxU9ftufP2IQAsXryYQ/seQJfOHTm07wEsWbIky5Hmn6Ii8cGjf+TpIWcDsPkmLRk3bBDTRg9m+PUDqVc3PM6/Qb26DL9+INNGD2bcsEG0L26RzbAzIo0HH7IbX7YDcIWpbt26XH/jLUyaOoO33/2Q++69i5kzZnDzjdfTe9/9mDbzC3rvux8333h9tkPNO+ed3IfPZq8bi891F/TjjpFv0qXf1SxZtoLTj+oFwOlH9mLJshV06Xc1d4x8k+su6JetkDOipGpvqiXbPOG6WlFcXEz3nXYCoHHjxnTq1Jm5c+fw/HOjGXDKaQAMOOU0nhszKotR5p92bZrRd8/teejZ99et22eXbXjmtUkAjHzuIw7v3RWAw3rvyMjnPgLgmdcm0XvXbTMfcIZ5C9et97768ksmT57ELrv2ZMH8+RQXhwd3Nt54YxbMn1/B0S7ppouP4fIho1i7NhRdadmsIUuXrWDNmrUAzJm/hE3aNAVgkzZN+ebb0GWzZs1afli+gpbNGmYn8AxRBf9lmydcV6uWL1/OSccfw0233EaTJk3+a5uknJ+hP5ccvFcXFixexqSZX1e883ooH7oUam2UgqQOwPNm1qWKxy83s0aVPGYscLKZfV9q/VXAcjO7uSqxlHGd+sALQCvgb8Bc4F5gFdDLzFZU4lxHAp+b2YyaiC2XrFq1ipOOP4YTTurPkUcdDUCbtm2ZN28excXFzJs3j9Zt2mQ5yvzRq9uWHLbPDvTdc3vqb1CPJg035OaLj6Vp4wbUqVPEmjVrade2OXMXLAVg7oKlbLpxc+Ys+J46dYpo0qgBi77/Mcs/RS3KkW6DVAqqhWtmh5ROtrWke7xeNzN7HOgP/C2+TzvZRkcC29VwfFlnZpz9mzPYtlNnLvjDhevWH3rYEYwYPhSAEcOHctjhhX0jpyZdeccYtu77ZzodOphTL32It8Z/zsDLhzJuwuccvX93APof3pPn35oKwAtvf0L/w3sCcPT+3Xl7/OdZiz1TaqDiQ62q7YRbR9IDkqZLekVSA0m/kTRe0hRJT0vaCEDSFpI+kPSJpL+kOqmkYknjYn2haZL2iuu/lNQqvr5c0ueS3gW2TRy7laSXJE2U9I6kTimu0zrGOD4ue0hqA4wAdonXPws4HrhW0sh43MVx/6mSrk6c79S4boqk4ZJ2B44Aborn2krS+ZJmxP0eKyeuM0vm8/xu4Xdp/Y/ItPffe49HRg7n7TffoOfO3ei5czdeenEsgy65lDdee5UunTvy5uuvMeiSS7Mdat67fMhozh/Qh2mjB9Oy6UY8POoDAB4e9T4tm27EtNGDOX9AH664fXSWI61dNVHTrNZjNKudiuexS2EW0MPMJsdZdcYAL5rZorjPX4D5ZnaHpDHAU2Y2TNK5wA3ldSlIugjY0MyuizWENjKzZZK+BHoAmxNqE/UkdJt8DNxrZjdLeh0428y+kNST0DLdt5zrPALcbWbvSmoPvGxmnSX1BgaZ2WFxv4cJ3SdPSToQOJYwo5Diz3wjsAh4FtjdzBZKamFmi5PHxnPNBbYws5WSmlXUYt955x723kcTUu3iqqH5LudlO4SCtvKzJ1j704IayYSdd+huD416M+U+vbZuPrGy8+HWpNp+0my2mU2OrycCHYAuMdE2AxoBL8ftewDHxNfDgRtSnHc88E9J9YBRiWuU2At41sx+AojJHEmNgN2BJxM3a+qnuM7+wHaJfZvEc6RyYFwmxfeNCPNkdgWeNLOFkLJm3FRgpKRRwKgKruWcS8j1PtzaTrgrE6/XAA0ILc8jzWyKpNMJc0+WSKu5bWbjJO0NHAo8LOnvZjYsjUOLgO/NrFs614n772ZmPydXVnBnXYRW832ljvldmtc8FNgbOBy4XNIOZrY6zWOdW6/ldrrNzk2zxsC82Drtn1j/HqHkMKXW/w9JmxO6Ih4A/gHsVGqXccCRsc+4MSF5YWY/ALMlHRfPI0ldU1zqFWBdooyTEFfkZeBXJS1hSe1iv+8bwHGSWsb1Jc9ZLiN8JkgqAjYzszeBPwJNCS1k51wFxC9DDctbKjxHKBK5QNK0xLoWkl6V9EX8s3lcL0m3S5oV77mUzkP/IxsJ98/AR4QE+2li/QXAuZI+oYLKl4RW8RRJk4ATgCHJjWb2MfA4MAV4kdAFUaI/cIakKcB0Qqnj8pwP9Igf5gzg7AriwsxeAR4BPog/y1NAYzObTpio+O147b/HQx4DLo4/S0dgRDxuEnB7hkZdOJf/4uQ1qZY0PAz0LbXuUuB1M+sIvB7fAxxM+J3tCJxJKDaZOsTaumnmMsNvmtUuv2lWu2ryptl2O3a3EWPeTrnPzls0rfCmmUo9QyDpM6C3mc1TqG/2lpltK+m++PrR0vuVd26fntE5VyDS6jZoJSnZQrnfzO6v4Ji2iST6LdA2vm4HJB/7+yauy8+EK2kHwoiFpJVm1rOGr3M5cFyp1U/GekXOuTyRRrdBpcukJ5mZSapyt0BOJ1wz+wToloHrVKoQnHMu94SbZrVy6vmSihNdCgvi+jnAZon9No3rylVQj/Y659ZvtTRb2BjgtPj6NGB0Yv2pcbTCbsDSVP23kOMtXOecq4zqzggm6VHCKKhWkr4BBgPXA09IOgP4ivAoP8BY4BDCE7U/AQMrOr8nXOdcYaiBGWrM7KRyNu1Xxr4GnFuZ83vCdc4VhDAfbm4/a+YJ1zlXMHI73XrCdc4VkHQe380mT7jOuYKR4/nWE65zrnDkeL71hOucKwwls4XlMk+4zrnCkP6MYFnjCdc5VzA84TrnXEZU6/HdjPCE65wrCOHBh2xHkZonXOdc4fCE65xzmeGP9jrnXIbkdrr1hOucKxQ+LMw55zKjph58kPQlsAxYA6w2sx6SWhAqgXcAvgSON7MllT23V3xwzhUMVbBUQh8z65aof1ZeqfRK8YTrnCsYRVLKpRr6AUPj66HAkVWKrzoROOdcTqm4idtK0oTEcmYZZzHgFUkTE9vLK5VeKd6H65wrCFJaDz6kUyZ9TzObI6kN8KqkT5Mbq1Mq3Vu4zrmCURNVe81sTvxzAfAssCuxVDpAqVLpleIJ1zlXMKTUS8XHq6GkxiWvgQOBaZRfKr1SvEvBOVcwamBUWFvg2Ti8rC7wiJm9JGk8ZZdKrxRPuM65giCqPRIBM/s30LWM9Ysoo1R6ZXmXgnPOZYi3cJ1zBcMf7XXOuUyQzxbmnHMZUYXHdzPOE65zrmB41V7nnMuQHM+3nnCdc4XDE65zzmVIrlftlVmV5mBwOULSd4QnX/JFK2BhtoMoYPn2+W5uZq1r4kSSXiL8/KksNLO+NXG9qvCE6zJK0oQ0ZmtyVeSfb27zJ82ccy5DPOE651yGeMJ1mXZ/tgMocP755jDvw3XOuQzxFq5zzmWIJ1znnMsQT7jOOZchnnCdcy5DPOE651yGeMJ1eU9xTj5JO0nqpFyfoy+PJT7rjbMdSz7yhOvynpmZpIOBJ4Em5mMda4Ukxc+6LzBU0ub+j1vl+Dhcl7cSCWALYCxwgplNlbQt0AyYbmbLsxpkgZG0N/BP4FQze19SAzNbke248oUnXJd3JDUENjSzRZI6Aj8AFwKrgDrAHsB3wGtmdk/2Is1/kuoSvkSskVQPOIfwOT8CHAecAXxoZn/IYph5w7sUXD7qBNwt6RzgVmATYCawGTAO6Ae8RsVT9bkUJNUH9gI2l9QPGAB8AlxL6L5pClwO9JLUPWuB5hGfgNzlHTObKGkZcAtwjplNkjQdGBq7GHYBfk1IBq7q/gN0BP4MdADONrM3Je0BLDaz7yS1B+oBy7IXZv7wFq7LG4k75C0ILdr7gHMk7WBm/4nJtgdwEfAXM3vJb+pUjaSiePNxNKGbZhowT9JGZvZZTLbHAS8D15rZrGzGmy+8D9fllfjV9gTgj2b2taRLCH2JBwP1gZOBx+I2+YiFykvcjNwP6AKMBH5D6LJ5yszekNQU2AGob2av+2edHm/hurwhqRcwGLjLzL4GMLMbgaeAD4HXgY8T2zwBVEFMtocR+sc/NbOFwE2E0j1HSboSmAR8bWavlxyTtYDziLdwXd6QdBLQ1cwulbQhsJLwd3itpF2BVWY2KbtR5r/42d4PPGBm70jawMz+E0csnAxsD7xrZs9lNdA85DfNXM4q42vqKsIvO2b2c9ynV+xvfDcbMRaoNYQRHp2BdwifO8CmZjasZCfvRqg871JwOUlSnfjV9gBJv5F0lpk9BTSV9JCkLSXtD4zA/x5XS+Jm5JaStiQk3IeA9pJ2j/8fdgMelrR1yXGebCvPW7gup0hqaGY/xoH2hwB/AS4D7osPPPQBHueXoUrnmdm4rAWc5+K3g7WSjgQGAV8BC4B3gR+Bv0qaBewD/MFHI1SP9+G6nCGpM/B7QpKdA9wD3EC4U34JcIqZzU7s38rMFvpX28qT1AlobGbjJW0D/APoC1wAHAHsCTQGNib8w/atmU32z7p6vIXrcoKkDYC/A3cB3xJ+0VcREkAX4FdmNlvS8YSbY88Ci8G/2lZWnOnrbeDUuGo58AFwInA44R+2NZK2MrOJwKclx/pnXT3e9+WyLk4+U58wrOsawpCj+YQkcC5ws5l9HvsRr47bMLO12Yk4f8VumZbAcKCZpIcJT4p1IMxH8SszmyXpIMLj05tmK9ZC5AnXZZWkzYH3CPMjTAQ2B1aY2RozG0lIAndLupPQxXCJmb2ftYDzmKTtCI9DrwS2BR4A3jKzr4BXgPeBAZIGEMbgXmtm32Qr3kLkfbguq+I8tvsQZp86BXiBMPnMdsBRZvaTpN0JM4IVxekXvR+xkuLY2meB0WZ2r6SLgF6Ef+RGEboN9iP03dYjJOJX/bOuWZ5wXVbF/sRXgXbAkWY2Ln7tvTWuO9bnW60Z8cGR8wifazfCHAnXAUuBh8zs07hfHTNbk604C5l3KbisiUOSviW0rmYDm0pqbGY/AucDi4AxPgFNjVkE7EwY+iUzW0RIuBsBZ0raKe7nfeO1xFu4LuNKVWr4lvAL3wh4mDDP6lAz+zF+Dd7azKZlL9r8luwSiBPObEnowtkH+JOZzYz96H8CbjGzz7MXbeHzhOuyQtIRhLG1kwAR5q7tTBil8ALwoJfHqZ7EP2yHEvprGwFXABsAvwV2BK4ysxmS6pvZyiyGu17wLgWXcXGg/RWEMZ8/EW6QFZnZh8CVwDFAi+xFWBhKHo0mDKV7DDgQuNPMFgMPAp8Bf4t95qvKP5OrKf7gg8uGhoQbZXsCewMDzGyJpB5m9qGkw81saXZDLBh7A2cThtstIUxvCaEr5xagVewzdxngCddlw2xgF8JE4n3iZOF9gQslnWJm87MbXkFZCfwBaAOcbmZfxdEKbc3sNuD7LMa23vEuBZcNywmThr8CnB77GG8ifN31ZFuzXgcOAh41sy/i03p/JpTMcRnmN81cVsS6ZDsQHnZYBLxtZmN9oH3NSdw0OwT4GzAZ2Ab4q08enh2ecF3WJaYI9GRbwxJJdzNC90LDOAmQf9ZZ4AnX1bjEL/m2wIbAl+XdBCs1TtSTQCUlPus6wNp0Pz9/miw7POG6WhEntL6MUM68PjAkDvtK7lMnTgPYGGhkZvMyH2n+KjXO9mTCfBNvmdnjZexb8lnXMzMfApYlftPM1QhJRfHPOpI6EAbW9yHMBLY18FnyEd1EAmhKmJt1k8xHnd9ist0PuAq4kTDq6Pw4t/A6ic+6GXBXnL/CZYEnXFdtktoA42MFhjWEv1efAGcBA4ETzWwJsJukjUol22eA8+NE164CklpLOjyxalPgHGAzQoHNky1U2G0X909+1s8CI+L8FS4LPOG6ajOzBcCHwLuSWpjZv4EmwK+Ac8zs/2JL7F6gOJEAXgEGm1fcTUv8FnEM0E/S0XF1Q8IcFBcRprP8Ko5pPk9So0TLdjTwZ/P6b1nlfbiuWiTVNbPVkloDYwnP6e8JdAV+TRhz+zmhFXaxmT0fj9uD8DjvO9mJPL+Uurl4OaEE0dOE7pjRhN/lwyUdCAwhFHx8SVI9wlSXT3iyzT5PuK7a4lfcK4D7gZMIX3N3BoqBg4EGwL/M7K2SflwfjVA1cW6ES4HmhMdzhxD6yUcS5kNoDdxgZmMTx7Q2s++yEK4rxROuq7R406W9mf0rvr8b+MTM7onv7wJ2B/aNcyT40K8qSo4qUKgvNoowIuFbwhwJ7QlPkb0Xh4Y1N7OFcX8f+pVjvA/XVYqkukBv4AdJjeLqxUCzuF3AtYTZvj6M+6/7e+bJNn2SWgHD4rzA8MvcJ6vN7AdCafM2hBm/jonJdVHJ8Z5sc48nXFcpZraa0Ge4ELhdod7YCOAiSSfGhNoBGEaYLGW1/+JXTWypXg60l7StmX1JmGXtGEnt4zSLzwDfEUaF+D9oOc4TrktbyVhbwoThqwjzqZ5OKMlyAHCFpH8Sqja8b2YfZCPOQhC7B4gjPk4GXooVMsYQWrV3Sfo9YbrFO71SQ37wPlyXlsRTTQcBpxKGfG1CqLDbFbgBmEPoWmhiZtOzFWu+S3zWuwE/mtknkq4CDgWOBVbE11sA48zstexF6yrDE65LW0y2txPG1r4R1zUiJN/dCJVfX81iiAVDoXz8XcBpJUPnJF0JHAH0N7PPSib9yWacrnJ8AnKXlsTNst8CH0g6njDO9g5Cf20dwp1zV00KRR1vAI4xs0mSugGNzewaSQY8K6kHoaXr8oi3cF3aJF1AGAP6MeHJspWEcbd9CF99fVKUGiCpAaEO2QaAEYo9LgPeMLPbJW3jfbb5yVu4Lm1mNkTSTOCz+AhpMaEQ5EZm9n12oysoa4EJwF6Em2SXAv0JE7YDzMpSXK6avIXr0lK6v1ChLtafCHMhPJO9yPJfRQ8oSOoJ3A1cYWYvZi4yV9N8WJhLSxk3Z+oAfzSzZ5LTLrr0SNpC0i0QHlAoGQZWxn47AL8HrjWzF/2zzm/ewnXrJIYjbUJ4YqmemS33u+E1T1JD4P+AJ83sd3Hd/7R04+QzLc3sW5+HIv95C9etE5NtX8IsVPcC/5S0tYV6Y+v+rsQRC0hqIGnrLIWbtyRtYGY/AgcCAyTdBOW2dFeXJFtPtPnPE65bR9I2wG3AJYQqr/8CRkrarKSFG1thqxNzrPrfoUqKE4QfRZhh7QHgNEn3xW3rkm78rE1Sc2C4pPqedPOb/7Ks50r1Ca4E3okD7WeZ2c3AR8C+cd+6iQmtnwCu8+FJlSdpI+B84BEzuwTYFugt6e+wLukmP+vHgX+a2cqsBe1qhA8LW8/FFtQ+QCfgK+BQSQPN7KG4y/dAy7jv6lipYRSheoBPHl41Kwn9t/MA4hSWvwdeiP3lv4+fdXNCsr3WP+vC4Al3PZW4QVYy5OgzYAZh9qnrFOqUfUF4lPQPiUNPAy7ziWnSl/is25nZnNhy/RQYKqm7ma0gVNy9mTAbWEk/+VDgb55sC4ePUliPSdoVuAa4xMymShoAbEko39KaUOL8X2b2fCJp+KTWVaBQyvxPwDvAd2Z2i6S/AocArwEnEoptvhu7eeoCzbxSQ2HxFu76rRmwP2FqxanAY8DxwIaE1u1tMcmuu0PuybbyJO1JuAl5FKHY40Fx6N0gwpNkzYBRFotpxs96FWGeW1dA/KbZeszMXgGOBn4l6aQ4ufjjwDTg5USS9a9BlVRqeFdL4ARgG6An8Of4+nZgtpm9ZF65eL3gLdz1nJmNkbQauDaODx0KPJLtuPKVpMZmtiz20/YhVL+YTrhBdhbwKzObIulYQiHIVsD8rAXsMsoTrsPMxsabNNdLehX41p8sq7w43OsFSbcDUwjz2c4glI2fDvQC5kjaAOgMnOETta9f/KaZW0deTrva4gMNlxIKa14aW7MnE1q6mxBmAPs/QqXdJ7MWqMsKT7jO1TBJBxAeDPmrmd0Uvz2cQHjA4WfgXjNb7I/rrn/8pplzNSyWGRoInJ64GfkYYazzsxaq7frNyPWQt3CdqyWSDgGuBW6PNyPdes4TrnO1SNIRwPWE8c5+M3I95wnXuVrmNyNdCU+4zjmXIX7TzDnnMsQTrnPOZYgnXOecyxBPuM45lyGecF1OkbRG0mRJ0yQ9GecnqOq5Ho6TxCDpH5K2S7Fvb0m7V+EaX0pqle76Uvssr+S1rpI0qLIxutzhCdflmhVm1s3MugD/Ac5ObiypGFxZZvZrM5uRYpfeQKUTrnOV4QnX5bJ3gK1j6/MdSWOAGZLqSLpJ0nhJUyWdBaGUjaQ7JX0m6TWgTcmJJL0lqUd83VfSx5KmSHpdUgdCYv9DbF3vJam1pKfjNcZL2iMe21LSK5KmS/oHICogaZSkifGYM0ttuzWuf11S67huK0kvxWPekdSpRj5Nl3U+PaPLSbElezDwUly1E9DFzGbHpLXUzHaRVB94T9IrQHfCBDHbAW0JUyP+s9R5WxNKk+8dz9UiTiRzL7A8VipG0iPArbHkTXvgZcKUioOBd83smlg254w0fpxfxWs0AMZLetrMFgENgQlm9gdJV8ZznwfcD5xtZl8kas7tW4WP0eUYT7gu1zSQNDm+fgd4kPBV/19mNjuuPxDYsaR/FmgKdAT2Jkx7uAaYK+mNMs6/GzCu5FwlE8mUYX9gO/1SRb6JpEbxGkfHY1+QtCSNn+n8OG0jwGYx1kXAWkKFDYARwDPxGrsDTyauXT+Na7g84AnX5ZoVZtYtuSImnh+Tq4DfmdnLpfY7pAbjKAJ2M7Ofy4glbZJ6E5J3LzP7SdJbhJpxZbF43e9LfwauMHgfrstHLwPnSKoHIGkbSQ2BccAJsY+3GOhTxrEfAntL2iIe2yKuXwY0Tuz3CvC7kjeSusWX44CT47qDCWVyUmkKLInJthOhhV2iCChppZ9M6Kr4AZgt6bh4DUnqWsE1XJ7whOvy0T8I/bMfS5oG3Ef4tvYsodrwDGAY8EHpA+MkMmcSvr5P4Zev9M8BR5XcNAPOB3rEm3Iz+GW0xNWEhD2d0LXw/yqI9SWgrqSZhFnDPkxs+xHYNf4M+xJK1gP0B86I8U0H+qXxmbg84JPXOOdchngL1znnMsQTrnPOZYgnXOecyxBPuM45lyGecJ1zLkM84TrnXIZ4wnXOuQz5/1h7KPYS48MwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
